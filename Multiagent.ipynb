{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Imports"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-14T13:23:48.847798100Z",
     "start_time": "2025-05-14T13:23:39.394720800Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Alonso\\Desktop\\Clase\\Master\\UPM\\TFM\\Trabajo\\venv\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import PyPDF2\n",
    "import boto3\n",
    "import nltk\n",
    "import jiwer\n",
    "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n",
    "from rouge import Rouge\n",
    "from tensorflow import keras\n",
    "from qdrant_client import QdrantClient\n",
    "from qdrant_client.http.models import PointStruct, VectorParams\n",
    "from sentence_transformers import SentenceTransformer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Embeddings Qdrant"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-14T13:23:51.441275600Z",
     "start_time": "2025-05-14T13:23:48.853392300Z"
    }
   },
   "outputs": [],
   "source": [
    "# %% [markdown]\n",
    "# ## Paso 2: Configuración de Qdrant, Amazon Bedrock y variable de modelos\n",
    "# Ajusta el host/puerto de Qdrant y el ID del modelo de Amazon Bedrock según tu configuración.\n",
    "\n",
    "# Inicializamos el cliente de Qdrant\n",
    "qdrant = QdrantClient(host=\"localhost\", port=6333)  # Cambia estos parámetros según tu entorno\n",
    "collection_name = \"documentos\"\n",
    "\n",
    "# Variable de modelos (ejemplo); se debe configurar con el id del modelo en Amazon Bedrock\n",
    "modelos = {\n",
    "    \"Titan Embeddings G1 - Text\" : \"amazon.titan-embed-text-v1\",\n",
    "    \"Titan Text G1 - Lite\": \"amazon.titan-text-lite-v1\",\n",
    "    \"Titan Text G1 - Express\": \"amazon.titan-text-express-v1\",\n",
    "    \"\": \"\",\n",
    "    \"Rerank_1.0\": \"amazon.rerank-v1:0\",\n",
    "    \"Claude_3.5_Sonnet\" : \"anthropic.claude-3-5-sonnet-20240620-v1:0\",\n",
    "    \"Claude_3_Sonnet\": \"anthropic.claude-3-sonnet-20240229-v1:0\",\n",
    "    \"Claude_3_Haiku\" : \"anthropic.claude-3-5-haiku-20241022-v1:0\",\n",
    "    \"Claude_2.1\" : \"anthropic.claude-v2:1\",\n",
    "    \"Claude_Instant\" : \"anthropic.claude-instant-v1\",\n",
    "    \"Claude\": \"anthropic.claude-v2:0\"\n",
    "}\n",
    "\n",
    "# Inicializamos el cliente de Amazon Bedrock\n",
    "bedrock = boto3.client('bedrock-runtime')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-14T13:23:54.869476200Z",
     "start_time": "2025-05-14T13:23:51.443344900Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Leyendo el PDF...\n",
      "PDF leído correctamente.\n"
     ]
    }
   ],
   "source": [
    "# %% [markdown]\n",
    "# ## Paso 3: Función para leer el PDF y extraer el texto\n",
    "\n",
    "def read_pdf(file_path):\n",
    "    \"\"\"Lee un PDF y extrae todo su texto.\"\"\"\n",
    "    text = \"\"\n",
    "    with open(file_path, 'rb') as pdf_file:\n",
    "        pdf_reader = PyPDF2.PdfReader(pdf_file)\n",
    "        for page in pdf_reader.pages:\n",
    "            page_text = page.extract_text()\n",
    "            if page_text:\n",
    "                text += page_text + \"\\n\"\n",
    "    return text\n",
    "\n",
    "# Ruta al documento\n",
    "pdf_path = \"documento.pdf\"\n",
    "print(\"Leyendo el PDF...\")\n",
    "document_text = read_pdf(pdf_path)\n",
    "print(\"PDF leído correctamente.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-14T13:23:54.875300900Z",
     "start_time": "2025-05-14T13:23:54.868321800Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dividiendo el documento en chunks...\n",
      "Total de chunks generados: 478\n"
     ]
    }
   ],
   "source": [
    "# %% [markdown]\n",
    "# ## Paso 4: Función para dividir el texto en chunks\n",
    "# Se define un tamaño de chunk y un solapamiento para conservar contexto entre ellos.\n",
    "\n",
    "def chunk_text(text, chunk_size=1000, overlap=100):\n",
    "    \"\"\"\n",
    "    Divide el texto en chunks de `chunk_size` caracteres con un solapamiento de `overlap` caracteres.\n",
    "    \"\"\"\n",
    "    chunks = []\n",
    "    start = 0\n",
    "    while start < len(text):\n",
    "        end = start + chunk_size\n",
    "        chunk = text[start:end]\n",
    "        chunks.append(chunk)\n",
    "        start += (chunk_size - overlap)\n",
    "    return chunks\n",
    "\n",
    "print(\"Dividiendo el documento en chunks...\")\n",
    "chunks = chunk_text(document_text, chunk_size=1000, overlap=100)\n",
    "print(f\"Total de chunks generados: {len(chunks)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-14T13:24:08.698112900Z",
     "start_time": "2025-05-14T13:23:54.875300900Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computando embeddings de los chunks...\n"
     ]
    },
    {
     "data": {
      "text/plain": "Batches:   0%|          | 0/15 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "fae1ed126b76406eb4a2b3346bec81ba"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subiendo los embeddings a Qdrant...\n",
      "Embeddings subidos correctamente.\n"
     ]
    }
   ],
   "source": [
    "# %% [markdown]\n",
    "# ## Paso 5: Calcular embeddings y subir a Qdrant\n",
    "# Se usa un modelo de SentenceTransformer para obtener los embeddings de cada chunk.\n",
    "# Si la colección en Qdrant no existe, se crea con la dimensión correcta.\n",
    "\n",
    "# Inicializamos el modelo de embeddings\n",
    "embedder = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "# Obtenemos la dimensión del embedding\n",
    "dimension = embedder.get_sentence_embedding_dimension()\n",
    "\n",
    "# Creamos la colección en Qdrant si no existe\n",
    "collections = qdrant.get_collections().collections\n",
    "if not any(col.name == collection_name for col in collections):\n",
    "    print(\"Creando colección en Qdrant...\")\n",
    "    qdrant.create_collection(\n",
    "         collection_name=collection_name,\n",
    "         vectors_config=VectorParams(size=dimension, distance=\"Cosine\")\n",
    "    )\n",
    "    print(\"Colección creada.\")\n",
    "\n",
    "print(\"Computando embeddings de los chunks...\")\n",
    "embeddings = embedder.encode(chunks, show_progress_bar=True)\n",
    "\n",
    "# Preparamos los puntos (cada punto asocia un chunk y su embedding)\n",
    "points = []\n",
    "for i, (chunk, vector) in enumerate(zip(chunks, embeddings)):\n",
    "    points.append(PointStruct(\n",
    "         id=i,\n",
    "         vector=vector.tolist(),\n",
    "         payload={\"text\": chunk}\n",
    "    ))\n",
    "\n",
    "print(\"Subiendo los embeddings a Qdrant...\")\n",
    "qdrant.upsert(collection_name=collection_name, points=points)\n",
    "print(\"Embeddings subidos correctamente.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-14T13:24:08.698112900Z",
     "start_time": "2025-05-14T13:24:08.694810900Z"
    }
   },
   "outputs": [],
   "source": [
    "# %% [markdown]\n",
    "# ## Paso 6: Función para recuperar chunks relevantes desde Qdrant\n",
    "# Dada una query, se calcula su embedding y se buscan los chunks más similares.\n",
    "\n",
    "def get_relevant_chunks(query, top_k=5):\n",
    "    \"\"\"\n",
    "    Dada una query, recupera los `top_k` chunks más relevantes desde Qdrant.\n",
    "    \"\"\"\n",
    "    query_embedding = embedder.encode(query)\n",
    "    search_result = qdrant.search(\n",
    "         collection_name=collection_name,\n",
    "         query_vector=query_embedding.tolist(),\n",
    "         limit=top_k\n",
    "    )\n",
    "    # Extraemos el texto de cada chunk recuperado\n",
    "    contexts = [res.payload.get(\"text\", \"\") for res in search_result]\n",
    "    return contexts"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Multi-agent System"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from qdrant_client import QdrantClient\n",
    "# Integración de Amazon Bedrock via LangChain AWS\n",
    "from langchain_aws import BedrockLLM\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain_qdrant import QdrantVectorStore\n",
    "from langchain.chains import RetrievalQA"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-14T13:24:09.287720500Z",
     "start_time": "2025-05-14T13:24:08.695914800Z"
    }
   },
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Invalid `embeddings` type.",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[10], line 22\u001B[0m\n\u001B[0;32m     10\u001B[0m BEDROCK_MODEL_ID \u001B[38;5;241m=\u001B[39m os\u001B[38;5;241m.\u001B[39mgetenv(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mBEDROCK_MODEL_ID\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mamazon.titan-text-express-v1\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m     12\u001B[0m \u001B[38;5;66;03m# ---------------------------------------------------------\u001B[39;00m\n\u001B[0;32m     13\u001B[0m \u001B[38;5;66;03m# Inicialización\u001B[39;00m\n\u001B[0;32m     14\u001B[0m \u001B[38;5;66;03m# ---------------------------------------------------------\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m     20\u001B[0m \n\u001B[0;32m     21\u001B[0m \u001B[38;5;66;03m# VectorStore basado en Qdrant\u001B[39;00m\n\u001B[1;32m---> 22\u001B[0m vectorstore \u001B[38;5;241m=\u001B[39m \u001B[43mQdrantVectorStore\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m     23\u001B[0m \u001B[43m    \u001B[49m\u001B[43mclient\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mqdrant\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     24\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcollection_name\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcollection_name\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     25\u001B[0m \u001B[43m    \u001B[49m\u001B[43membedding\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43membedder\u001B[49m\n\u001B[0;32m     26\u001B[0m \u001B[43m)\u001B[49m\n\u001B[0;32m     28\u001B[0m \u001B[38;5;66;03m# Recuperador de los top_k chunks relevantes\u001B[39;00m\n\u001B[0;32m     29\u001B[0m retriever \u001B[38;5;241m=\u001B[39m vectorstore\u001B[38;5;241m.\u001B[39mas_retriever(search_kwargs\u001B[38;5;241m=\u001B[39m{\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mk\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;241m5\u001B[39m})\n",
      "File \u001B[1;32m~\\Desktop\\Clase\\Master\\UPM\\TFM\\Trabajo\\venv\\Lib\\site-packages\\langchain_qdrant\\qdrant.py:213\u001B[0m, in \u001B[0;36mQdrantVectorStore.__init__\u001B[1;34m(self, client, collection_name, embedding, retrieval_mode, vector_name, content_payload_key, metadata_payload_key, distance, sparse_embedding, sparse_vector_name, validate_embeddings, validate_collection_config)\u001B[0m\n\u001B[0;32m    210\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_validate_embeddings(retrieval_mode, embedding, sparse_embedding)\n\u001B[0;32m    212\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m validate_collection_config:\n\u001B[1;32m--> 213\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_validate_collection_config\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    214\u001B[0m \u001B[43m        \u001B[49m\u001B[43mclient\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    215\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcollection_name\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    216\u001B[0m \u001B[43m        \u001B[49m\u001B[43mretrieval_mode\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    217\u001B[0m \u001B[43m        \u001B[49m\u001B[43mvector_name\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    218\u001B[0m \u001B[43m        \u001B[49m\u001B[43msparse_vector_name\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    219\u001B[0m \u001B[43m        \u001B[49m\u001B[43mdistance\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    220\u001B[0m \u001B[43m        \u001B[49m\u001B[43membedding\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    221\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    223\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_client \u001B[38;5;241m=\u001B[39m client\n\u001B[0;32m    224\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcollection_name \u001B[38;5;241m=\u001B[39m collection_name\n",
      "File \u001B[1;32m~\\Desktop\\Clase\\Master\\UPM\\TFM\\Trabajo\\venv\\Lib\\site-packages\\langchain_qdrant\\qdrant.py:1050\u001B[0m, in \u001B[0;36mQdrantVectorStore._validate_collection_config\u001B[1;34m(cls, client, collection_name, retrieval_mode, vector_name, sparse_vector_name, distance, embedding)\u001B[0m\n\u001B[0;32m   1038\u001B[0m \u001B[38;5;129m@classmethod\u001B[39m\n\u001B[0;32m   1039\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21m_validate_collection_config\u001B[39m(\n\u001B[0;32m   1040\u001B[0m     \u001B[38;5;28mcls\u001B[39m: Type[QdrantVectorStore],\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   1047\u001B[0m     embedding: Optional[Embeddings],\n\u001B[0;32m   1048\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m   1049\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m retrieval_mode \u001B[38;5;241m==\u001B[39m RetrievalMode\u001B[38;5;241m.\u001B[39mDENSE:\n\u001B[1;32m-> 1050\u001B[0m         \u001B[38;5;28;43mcls\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_validate_collection_for_dense\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   1051\u001B[0m \u001B[43m            \u001B[49m\u001B[43mclient\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcollection_name\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mvector_name\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdistance\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43membedding\u001B[49m\n\u001B[0;32m   1052\u001B[0m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1054\u001B[0m     \u001B[38;5;28;01melif\u001B[39;00m retrieval_mode \u001B[38;5;241m==\u001B[39m RetrievalMode\u001B[38;5;241m.\u001B[39mSPARSE:\n\u001B[0;32m   1055\u001B[0m         \u001B[38;5;28mcls\u001B[39m\u001B[38;5;241m.\u001B[39m_validate_collection_for_sparse(\n\u001B[0;32m   1056\u001B[0m             client, collection_name, sparse_vector_name\n\u001B[0;32m   1057\u001B[0m         )\n",
      "File \u001B[1;32m~\\Desktop\\Clase\\Master\\UPM\\TFM\\Trabajo\\venv\\Lib\\site-packages\\langchain_qdrant\\qdrant.py:1113\u001B[0m, in \u001B[0;36mQdrantVectorStore._validate_collection_for_dense\u001B[1;34m(cls, client, collection_name, vector_name, distance, dense_embeddings)\u001B[0m\n\u001B[0;32m   1111\u001B[0m     vector_size \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlen\u001B[39m(dense_embeddings)\n\u001B[0;32m   1112\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 1113\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mInvalid `embeddings` type.\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m   1115\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m vector_config\u001B[38;5;241m.\u001B[39msize \u001B[38;5;241m!=\u001B[39m vector_size:\n\u001B[0;32m   1116\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m QdrantVectorStoreError(\n\u001B[0;32m   1117\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mExisting Qdrant collection is configured for dense vectors with \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m   1118\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mvector_config\u001B[38;5;241m.\u001B[39msize\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m dimensions. \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   1121\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mparameter to `True`.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m   1122\u001B[0m     )\n",
      "\u001B[1;31mValueError\u001B[0m: Invalid `embeddings` type."
     ]
    }
   ],
   "source": [
    "# ---------------------------------------------------------\n",
    "# Configuración\n",
    "# ---------------------------------------------------------\n",
    "QDRANT_HOST = os.getenv(\"QDRANT_HOST\", \"localhost\")\n",
    "QDRANT_PORT = int(os.getenv(\"QDRANT_PORT\", 6333))\n",
    "COLLECTION_NAME = \"documentos\"\n",
    "# Perfil AWS para Bedrock (configurar en ~/.aws/credentials)\n",
    "BEDROCK_PROFILE = os.getenv(\"BEDROCK_PROFILE\", \"bedrock-admin\")\n",
    "# ID del modelo Bedrock a usar\n",
    "BEDROCK_MODEL_ID = os.getenv(\"BEDROCK_MODEL_ID\", \"amazon.titan-text-express-v1\")\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# Inicialización\n",
    "# ---------------------------------------------------------\n",
    "# Cliente Qdrant\n",
    "# qdrant_client = QdrantClient(host=QDRANT_HOST, port=QDRANT_PORT)\n",
    "# \n",
    "# # Embeddings con HuggingFace\n",
    "# embedder = HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
    "\n",
    "# VectorStore basado en Qdrant\n",
    "vectorstore = QdrantVectorStore(\n",
    "    client=qdrant,\n",
    "    collection_name=collection_name,\n",
    "    embedding=embedder\n",
    ")\n",
    "\n",
    "# Recuperador de los top_k chunks relevantes\n",
    "retriever = vectorstore.as_retriever(search_kwargs={\"k\": 5})\n",
    "\n",
    "# LLM de Amazon Bedrock\n",
    "llm = BedrockLLM(\n",
    "    credentials_profile_name=\"Claude_3.5_Sonnet\",\n",
    "    model_id=\"anthropic.claude-3-5-sonnet-20240620-v1:0\"\n",
    ")\n",
    "\n",
    "# Cadena RAG: recuperación + generación\n",
    "qa_agent = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    chain_type=\"refine\",\n",
    "    retriever=retriever,\n",
    "    return_source_documents=False\n",
    ")\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# Función principal de procesamiento\n",
    "# ---------------------------------------------------------\n",
    "def process_questions(input_json: str, output_json: str):\n",
    "    \"\"\"\n",
    "    Carga preguntas de `input_json`, consulta al agente Bedrock QA,\n",
    "    y salva en `output_json` con question/expected/generated.\n",
    "    \"\"\"\n",
    "    with open(input_json, 'r', encoding='utf-8') as f:\n",
    "        qa_list = json.load(f)\n",
    "\n",
    "    results = []\n",
    "    for item in qa_list:\n",
    "        question = item.get(\"Q\") or item.get(\"question\")\n",
    "        expected = item.get(\"A\") or item.get(\"expected_answer\")\n",
    "\n",
    "        # Invocar la cadena QA\n",
    "        output = qa_agent.invoke({\"query\": question})\n",
    "        generated = output.get(\"result\")\n",
    "\n",
    "        results.append({\n",
    "            \"question\": question,\n",
    "            \"expected_answer\": expected,\n",
    "            \"generated_answer\": generated.strip() if isinstance(generated, str) else generated\n",
    "        })\n",
    "\n",
    "    with open(output_json, 'w', encoding='utf-8') as f:\n",
    "        json.dump(results, f, ensure_ascii=False, indent=4)\n",
    "    print(f\"Resultados guardados en {output_json}\")\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# Ejecución si se lanza como script\n",
    "# ---------------------------------------------------------\n",
    "if __name__ == \"__main__\":\n",
    "    process_questions(\n",
    "        input_json=\"Expert-questions.json\",\n",
    "        output_json=\"Expert-questions-output.json\"\n",
    "    )\n",
    "    process_questions(\n",
    "        input_json=\"Not-expert-questions.json\",\n",
    "        output_json=\"Not-expert-questions-output.json\"\n",
    "    )\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-14T13:44:02.988124800Z",
     "start_time": "2025-05-14T13:44:00.883253700Z"
    }
   },
   "execution_count": 10
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
