{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-26T19:26:51.289186700Z",
     "start_time": "2025-02-26T19:26:51.282221300Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import PyPDF2\n",
    "import boto3\n",
    "import nltk\n",
    "import jiwer\n",
    "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n",
    "from rouge import Rouge\n",
    "from tensorflow import keras\n",
    "from qdrant_client import QdrantClient\n",
    "from qdrant_client.http.models import PointStruct, VectorParams\n",
    "from sentence_transformers import SentenceTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-26T19:26:53.787798900Z",
     "start_time": "2025-02-26T19:26:51.293667200Z"
    }
   },
   "outputs": [],
   "source": [
    "# %% [markdown]\n",
    "# ## Paso 2: Configuración de Qdrant, Amazon Bedrock y variable de modelos\n",
    "# Ajusta el host/puerto de Qdrant y el ID del modelo de Amazon Bedrock según tu configuración.\n",
    "\n",
    "# Inicializamos el cliente de Qdrant\n",
    "qdrant = QdrantClient(host=\"localhost\", port=6333)  # Cambia estos parámetros según tu entorno\n",
    "collection_name = \"documentos\"\n",
    "\n",
    "# Variable de modelos (ejemplo); se debe configurar con el id del modelo en Amazon Bedrock\n",
    "modelos = {\n",
    "    \"Titan Embeddings G1 - Text\" : \"amazon.titan-embed-text-v1\",\n",
    "    \"Titan Text G1 - Lite\": \"amazon.titan-text-lite-v1\",\n",
    "    \"Titan Text G1 - Express\": \"amazon.titan-text-express-v1\",\n",
    "    \"\": \"\",\n",
    "    \"Rerank_1.0\": \"amazon.rerank-v1:0\",\n",
    "    \"Claude_3.5_Sonnet\" : \"anthropic.claude-3-5-sonnet-20240620-v1:0\",\n",
    "    \"Claude_3_Sonnet\": \"anthropic.claude-3-sonnet-20240229-v1:0\",\n",
    "    \"Claude_3_Haiku\" : \"anthropic.claude-3-5-haiku-20241022-v1:0\",\n",
    "    \"Claude_2.1\" : \"anthropic.claude-v2:1\",\n",
    "    \"Claude_Instant\" : \"anthropic.claude-instant-v1\",\n",
    "    \"Claude\": \"anthropic.claude-v2:0\"\n",
    "}\n",
    "\n",
    "# Inicializamos el cliente de Amazon Bedrock\n",
    "bedrock = boto3.client('bedrock-runtime')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-26T19:26:57.096513600Z",
     "start_time": "2025-02-26T19:26:53.789855300Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Leyendo el PDF...\n",
      "PDF leído correctamente.\n"
     ]
    }
   ],
   "source": [
    "# %% [markdown]\n",
    "# ## Paso 3: Función para leer el PDF y extraer el texto\n",
    "\n",
    "def read_pdf(file_path):\n",
    "    \"\"\"Lee un PDF y extrae todo su texto.\"\"\"\n",
    "    text = \"\"\n",
    "    with open(file_path, 'rb') as pdf_file:\n",
    "        pdf_reader = PyPDF2.PdfReader(pdf_file)\n",
    "        for page in pdf_reader.pages:\n",
    "            page_text = page.extract_text()\n",
    "            if page_text:\n",
    "                text += page_text + \"\\n\"\n",
    "    return text\n",
    "\n",
    "# Ruta al documento\n",
    "pdf_path = \"documento.pdf\"\n",
    "print(\"Leyendo el PDF...\")\n",
    "document_text = read_pdf(pdf_path)\n",
    "print(\"PDF leído correctamente.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-26T19:26:57.096513600Z",
     "start_time": "2025-02-26T19:26:57.089910600Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dividiendo el documento en chunks...\n",
      "Total de chunks generados: 478\n"
     ]
    }
   ],
   "source": [
    "# %% [markdown]\n",
    "# ## Paso 4: Función para dividir el texto en chunks\n",
    "# Se define un tamaño de chunk y un solapamiento para conservar contexto entre ellos.\n",
    "\n",
    "def chunk_text(text, chunk_size=1000, overlap=100):\n",
    "    \"\"\"\n",
    "    Divide el texto en chunks de `chunk_size` caracteres con un solapamiento de `overlap` caracteres.\n",
    "    \"\"\"\n",
    "    chunks = []\n",
    "    start = 0\n",
    "    while start < len(text):\n",
    "        end = start + chunk_size\n",
    "        chunk = text[start:end]\n",
    "        chunks.append(chunk)\n",
    "        start += (chunk_size - overlap)\n",
    "    return chunks\n",
    "\n",
    "print(\"Dividiendo el documento en chunks...\")\n",
    "chunks = chunk_text(document_text, chunk_size=1000, overlap=100)\n",
    "print(f\"Total de chunks generados: {len(chunks)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-26T19:27:11.254291400Z",
     "start_time": "2025-02-26T19:26:57.099596100Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computando embeddings de los chunks...\n"
     ]
    },
    {
     "data": {
      "text/plain": "Batches:   0%|          | 0/15 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "59dde0dc98e34f75a451c4df63fbefe8"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subiendo los embeddings a Qdrant...\n",
      "Embeddings subidos correctamente.\n"
     ]
    }
   ],
   "source": [
    "# %% [markdown]\n",
    "# ## Paso 5: Calcular embeddings y subir a Qdrant\n",
    "# Se usa un modelo de SentenceTransformer para obtener los embeddings de cada chunk.\n",
    "# Si la colección en Qdrant no existe, se crea con la dimensión correcta.\n",
    "\n",
    "# Inicializamos el modelo de embeddings\n",
    "embedder = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "# Obtenemos la dimensión del embedding\n",
    "dimension = embedder.get_sentence_embedding_dimension()\n",
    "\n",
    "# Creamos la colección en Qdrant si no existe\n",
    "collections = qdrant.get_collections().collections\n",
    "if not any(col.name == collection_name for col in collections):\n",
    "    print(\"Creando colección en Qdrant...\")\n",
    "    qdrant.create_collection(\n",
    "         collection_name=collection_name,\n",
    "         vectors_config=VectorParams(size=dimension, distance=\"Cosine\")\n",
    "    )\n",
    "    print(\"Colección creada.\")\n",
    "\n",
    "print(\"Computando embeddings de los chunks...\")\n",
    "embeddings = embedder.encode(chunks, show_progress_bar=True)\n",
    "\n",
    "# Preparamos los puntos (cada punto asocia un chunk y su embedding)\n",
    "points = []\n",
    "for i, (chunk, vector) in enumerate(zip(chunks, embeddings)):\n",
    "    points.append(PointStruct(\n",
    "         id=i,\n",
    "         vector=vector.tolist(),\n",
    "         payload={\"text\": chunk}\n",
    "    ))\n",
    "\n",
    "print(\"Subiendo los embeddings a Qdrant...\")\n",
    "qdrant.upsert(collection_name=collection_name, points=points)\n",
    "print(\"Embeddings subidos correctamente.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-26T19:27:11.254291400Z",
     "start_time": "2025-02-26T19:27:11.252335800Z"
    }
   },
   "outputs": [],
   "source": [
    "# %% [markdown]\n",
    "# ## Paso 6: Función para recuperar chunks relevantes desde Qdrant\n",
    "# Dada una query, se calcula su embedding y se buscan los chunks más similares.\n",
    "\n",
    "def get_relevant_chunks(query, top_k=5):\n",
    "    \"\"\"\n",
    "    Dada una query, recupera los `top_k` chunks más relevantes desde Qdrant.\n",
    "    \"\"\"\n",
    "    query_embedding = embedder.encode(query)\n",
    "    search_result = qdrant.search(\n",
    "         collection_name=collection_name,\n",
    "         query_vector=query_embedding.tolist(),\n",
    "         limit=top_k\n",
    "    )\n",
    "    # Extraemos el texto de cada chunk recuperado\n",
    "    contexts = [res.payload.get(\"text\", \"\") for res in search_result]\n",
    "    return contexts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-26T19:27:11.261573500Z",
     "start_time": "2025-02-26T19:27:11.256363800Z"
    }
   },
   "outputs": [],
   "source": [
    "def ask_question(query, modelo, top_k=5):\n",
    "    # Recupera los chunks relevantes y construye el contexto\n",
    "    contexts = get_relevant_chunks(query, top_k=top_k)\n",
    "    context_text = \"\\n\".join(contexts)\n",
    "    \n",
    "    # Define el mensaje de sistema que contiene instrucciones y el contexto.\n",
    "    # En este ejemplo se indica que se debe responder en pocas palabras.\n",
    "    system_message = f\"Answer the question based on the following context shortly, in at most 5 words:\\n{context_text}\"\n",
    "    \n",
    "    # Define el mensaje del usuario con la consulta.\n",
    "    messages = [{\"role\": \"user\", \"content\": query}]\n",
    "    \n",
    "    # Construye el payload utilizando la estructura que funcionó en tu prueba.\n",
    "    payload = {\n",
    "        \"anthropic_version\": \"bedrock-2023-05-31\",  \n",
    "        \"system\": system_message,\n",
    "        \"messages\": messages,\n",
    "        \"max_tokens\": 100,\n",
    "        \"temperature\": 0.8,\n",
    "        \"top_p\": 0.8,\n",
    "    }\n",
    "    \n",
    "    # Convierte el payload a JSON\n",
    "    payload_json = json.dumps(payload)\n",
    "    \n",
    "    # Selecciona el id del modelo a partir del diccionario 'modelos'\n",
    "    model_id = modelos.get(modelo)\n",
    "    \n",
    "    # Invoca el modelo en Amazon Bedrock\n",
    "    response = bedrock.invoke_model(\n",
    "         modelId=model_id,\n",
    "         contentType=\"application/json\",\n",
    "         body=payload_json\n",
    "    )\n",
    "    \n",
    "    # Procesa la respuesta (para modelos Anthropic la respuesta suele estar en la clave \"content\")\n",
    "    response_body = json.loads(response[\"body\"].read().decode(\"utf-8\"))\n",
    "    return response_body.get(\"content\", response_body)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-26T19:27:11.266896900Z",
     "start_time": "2025-02-26T19:27:11.261573500Z"
    }
   },
   "outputs": [],
   "source": [
    "def extract_answer_text(generated_answer):\n",
    "    \"\"\"\n",
    "    Given the generated answer, which may be a list of dicts or a string,\n",
    "    extract and return the plain text.\n",
    "    \"\"\"\n",
    "    if isinstance(generated_answer, list) and len(generated_answer) > 0:\n",
    "        # Assume the answer is in the first element under the \"text\" key\n",
    "        return generated_answer[0].get(\"text\", \"\").strip()\n",
    "    elif isinstance(generated_answer, str):\n",
    "        return generated_answer.strip()\n",
    "    else:\n",
    "        return str(generated_answer).strip()\n",
    "\n",
    "# Modified evaluation function to include the expected answer (for later comparison)\n",
    "def evaluate_qa_pairs(qa_pairs, model_name=\"Claude_3.5_Sonnet\"):\n",
    "    results = []\n",
    "    for qa in qa_pairs:\n",
    "        question = qa[\"Q\"]\n",
    "        expected_answer = qa[\"A\"]\n",
    "        print(f\"Evaluando pregunta: {question}\")\n",
    "        \n",
    "        # Get the generated answer from RAG\n",
    "        generated_answer = ask_question(question, model_name)\n",
    "        answer_text = extract_answer_text(generated_answer)\n",
    "        \n",
    "        result = {\n",
    "            \"question\": question,\n",
    "            \"expected_answer\": expected_answer,\n",
    "            \"generated_answer\": answer_text\n",
    "        }\n",
    "        results.append(result)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-26T19:30:16.346744400Z",
     "start_time": "2025-02-26T19:27:11.264650600Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluando pregunta: ¿Qué son los riesgos ESG?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Alonso\\AppData\\Local\\Temp\\ipykernel_15372\\1406710426.py:10: DeprecationWarning: `search` method is deprecated and will be removed in the future. Use `query_points` instead.\n",
      "  search_result = qdrant.search(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluando pregunta: ¿Cuál es el objetivo principal de estas directrices ESG?\n",
      "Evaluando pregunta: ¿Por qué es importante que las instituciones gestionen los riesgos ESG?\n",
      "Evaluando pregunta: ¿Qué se entiende por riesgo ambiental en este contexto?\n",
      "Evaluando pregunta: ¿Qué significa “riesgo de transición”?\n",
      "Evaluando pregunta: ¿Qué son los riesgos físicos en el ámbito ESG?\n",
      "Evaluando pregunta: ¿Qué papel tiene el EBA en la gestión de riesgos ESG?\n",
      "Evaluando pregunta: ¿Cómo deben integrar las instituciones los riesgos ESG en su gestión?\n",
      "Evaluando pregunta: ¿Qué es una evaluación de materialidad en riesgos ESG?\n",
      "Evaluando pregunta: ¿Qué debe incluir un plan de transición ESG?\n",
      "Evaluando pregunta: ¿Qué horizonte temporal se considera para los riesgos ESG?\n",
      "Evaluando pregunta: ¿Qué herramientas se pueden utilizar para medir los riesgos ESG?\n",
      "Evaluando pregunta: ¿Qué es un análisis de escenarios en este contexto?\n",
      "Evaluando pregunta: ¿Cómo se relacionan los riesgos ESG con la sostenibilidad?\n",
      "Evaluando pregunta: ¿Qué impacto pueden tener los riesgos ESG en la solvencia de una institución?\n",
      "Evaluando pregunta: ¿Cómo se comunica la información sobre riesgos ESG?\n",
      "Evaluando pregunta: ¿Qué importancia tiene la gobernanza en la gestión de riesgos ESG?\n",
      "Evaluando pregunta: ¿Cuáles son los principales desafíos en la medición de riesgos ESG?\n",
      "Evaluando pregunta: ¿Qué es el riesgo de reputación en relación con ESG?\n",
      "Evaluando pregunta: ¿Por qué es fundamental la integración de datos en la evaluación de riesgos ESG?\n",
      "Evaluando pregunta: ¿Cuáles son los principales componentes metodológicos para identificar y medir los riesgos ESG?\n",
      "Evaluando pregunta: ¿Cómo debe realizarse la evaluación de materialidad en el contexto ESG?\n",
      "Evaluando pregunta: ¿Qué criterios se utilizan para determinar la materialidad de un riesgo ESG?\n",
      "Evaluando pregunta: ¿Cómo se integran los riesgos ESG en los procesos de ICAAP e ILAAP?\n",
      "Evaluando pregunta: ¿Qué papel juegan los análisis de escenarios en la gestión de riesgos ESG?\n",
      "Evaluando pregunta: ¿Cuáles son los desafíos en la obtención y calidad de datos para evaluar riesgos ESG?\n",
      "Evaluando pregunta: ¿Qué implicaciones tiene la integración de riesgos ESG en el apetito de riesgo de una institución?\n",
      "Evaluando pregunta: ¿Cómo se aplican las metodologías de alineación de cartera en el análisis ESG?\n",
      "Evaluando pregunta: ¿Qué importancia tienen las evaluaciones de vulnerabilidad a riesgos físicos?\n",
      "Evaluando pregunta: ¿De qué forma se integran los riesgos de transición en los modelos de scoring crediticio?\n",
      "Evaluando pregunta: ¿Qué medidas de mitigación se recomiendan para gestionar riesgos ESG en carteras crediticias?\n",
      "Evaluando pregunta: ¿Cómo deben documentarse las metodologías y supuestos en la evaluación ESG?\n",
      "Evaluando pregunta: ¿Qué rol desempeñan los KRIs en la monitorización de riesgos ESG?\n",
      "Evaluando pregunta: ¿Cómo se deben integrar los riesgos ESG en la estructura de gobernanza interna?\n",
      "Evaluando pregunta: ¿Qué papel tienen los datos externos y de terceros en la evaluación de riesgos ESG?\n",
      "Evaluando pregunta: ¿Cómo se aborda la incertidumbre inherente a la medición de riesgos ESG?\n",
      "Evaluando pregunta: ¿Qué implicaciones regulatorias tienen estas directrices ESG para las instituciones financieras?\n",
      "Evaluando pregunta: ¿Cómo se relaciona el análisis ESG con los objetivos de sostenibilidad a largo plazo?\n",
      "Evaluando pregunta: ¿Qué papel desempeñan los planes de transición en la mitigación de riesgos ESG?\n",
      "Evaluando pregunta: ¿Cómo puede la integración de riesgos ESG mejorar la competitividad de una institución?\n"
     ]
    }
   ],
   "source": [
    "with open(\"Expert-questions.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    expert_qa = json.load(f)\n",
    "\n",
    "with open(\"Not-expert-questions.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    non_expert_qa = json.load(f)\n",
    "\n",
    "# Evaluar ambos conjuntos de preguntas\n",
    "non_expert_results = evaluate_qa_pairs(non_expert_qa, model_name=\"Claude_3.5_Sonnet\")\n",
    "expert_results = evaluate_qa_pairs(expert_qa, model_name=\"Claude_3.5_Sonnet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-26T19:30:16.356266800Z",
     "start_time": "2025-02-26T19:30:16.348764600Z"
    }
   },
   "outputs": [],
   "source": [
    "# Imprimir las respuestas obtenidas\n",
    "# print(\"\\nResultados para preguntas no expertas:\")\n",
    "# for res in non_expert_results:\n",
    "#     print(f\"Pregunta: {res['question']}\\nRespuesta: {res['answer']}\\n\")\n",
    "# \n",
    "# print(\"\\nResultados para preguntas expertas:\")\n",
    "# for res in expert_results:\n",
    "#     print(f\"Pregunta: {res['question']}\\nRespuesta: {res['answer']}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Save the results to separate JSON files\n",
    "with open(\"non_expert_results.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(non_expert_results, f, ensure_ascii=False, indent=4)\n",
    "\n",
    "with open(\"expert_results.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(expert_results, f, ensure_ascii=False, indent=4)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-26T19:30:16.363708800Z",
     "start_time": "2025-02-26T19:30:16.355253Z"
    }
   },
   "execution_count": 22
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
