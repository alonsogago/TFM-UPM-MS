{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-05-17T15:50:25.153801700Z",
     "start_time": "2025-05-17T15:50:22.870363400Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import PyPDF2\n",
    "from qdrant_client import QdrantClient\n",
    "from qdrant_client.http.models import PointStruct, VectorParams\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain_qdrant import QdrantVectorStore\n",
    "from langchain_aws import BedrockLLM\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.prompts import ChatPromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Parámetros Qdrant\n",
    "QDRANT_HOST = os.getenv(\"QDRANT_HOST\", \"localhost\")\n",
    "QDRANT_PORT = int(os.getenv(\"QDRANT_PORT\", 6333))\n",
    "COLLECTION_NAME = \"documentos\"\n",
    "\n",
    "# Parámetros Amazon Bedrock\n",
    "BEDROCK_PROFILE = os.getenv(\"BEDROCK_PROFILE\", \"bedrock-admin\")\n",
    "BEDROCK_MODEL_ID = os.getenv(\"BEDROCK_MODEL_ID\", \"amazon.titan-text-express-v1\")\n",
    "# Ajustes de generación\n",
    "LLM_MAX_TOKENS = 256\n",
    "LLM_STOP_SEQUENCES = [\"\\n\\n\"]  # corta generación tras doble salto"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-17T15:50:25.158057800Z",
     "start_time": "2025-05-17T15:50:25.153801700Z"
    }
   },
   "id": "d8ab0b11490ec1f0",
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Lee todo el texto de un PDF\n",
    "def read_pdf(file_path: str) -> str:\n",
    "    text = \"\"\n",
    "    with open(file_path, 'rb') as f:\n",
    "        reader = PyPDF2.PdfReader(f)\n",
    "        for page in reader.pages:\n",
    "            page_text = page.extract_text() or \"\"\n",
    "            text += page_text + \"\\n\"\n",
    "    return text\n",
    "\n",
    "# Divide texto en chunks con solapamiento\n",
    "def chunk_text(text: str, chunk_size: int = 1000, overlap: int = 100) -> list[str]:\n",
    "    chunks, start = [], 0\n",
    "    while start < len(text):\n",
    "        end = start + chunk_size\n",
    "        chunks.append(text[start:end])\n",
    "        start += chunk_size - overlap\n",
    "    return chunks"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-17T15:50:25.162073500Z",
     "start_time": "2025-05-17T15:50:25.159058100Z"
    }
   },
   "id": "ff585e65d8233502",
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Alonso\\Desktop\\Clase\\Master\\UPM\\TFM\\Trabajo\\venv\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "Leyendo PDF…\n",
      "Chunking…\n",
      "478 chunks generados.\n",
      "Calculando embeddings…\n",
      "Subiendo a Qdrant…\n",
      "Embeddings listos.\n"
     ]
    }
   ],
   "source": [
    "# 3.1 Iniciar cliente Qdrant y el embebedor\n",
    "qdrant_client = QdrantClient(host=QDRANT_HOST, port=QDRANT_PORT)\n",
    "embedder = HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
    "\n",
    "# 3.2 Leer y generar chunks\n",
    "pdf_path = \"documento.pdf\"\n",
    "print(\"Leyendo PDF…\")\n",
    "document_text = read_pdf(pdf_path)\n",
    "print(\"Chunking…\")\n",
    "chunks = chunk_text(document_text, chunk_size=1000, overlap=100)\n",
    "print(f\"{len(chunks)} chunks generados.\")\n",
    "\n",
    "# 3.3 Detectar dimensión del embedding\n",
    "try:\n",
    "    dimension = embedder.client.get_sentence_embedding_dimension()\n",
    "except AttributeError:\n",
    "    dimension = len(embedder.embed_query(\"prueba\"))  # fallback\n",
    "\n",
    "# 3.4 Crear colección Qdrant si es necesario\n",
    "existing = [col.name for col in qdrant_client.get_collections().collections]\n",
    "if COLLECTION_NAME not in existing:\n",
    "    print(\"Creando colección Qdrant…\")\n",
    "    qdrant_client.create_collection(\n",
    "        collection_name=COLLECTION_NAME,\n",
    "        vectors_config=VectorParams(size=dimension, distance=\"Cosine\")\n",
    "    )\n",
    "\n",
    "# 3.5 Calcular embeddings y subirlos\n",
    "print(\"Calculando embeddings…\")\n",
    "vectors = embedder.embed_documents(chunks)\n",
    "points = [PointStruct(id=i, vector=v, payload={\"text\": c})\n",
    "          for i, (c, v) in enumerate(zip(chunks, vectors))]\n",
    "print(\"Subiendo a Qdrant…\")\n",
    "qdrant_client.upsert(collection_name=COLLECTION_NAME, points=points)\n",
    "print(\"Embeddings listos.\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-17T15:51:07.887451400Z",
     "start_time": "2025-05-17T15:50:25.163075700Z"
    }
   },
   "id": "e891ecb37c41bdb3",
   "execution_count": 4
  },
  {
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-17T15:51:10.175713400Z",
     "start_time": "2025-05-17T15:51:07.889451400Z"
    }
   },
   "cell_type": "code",
   "outputs": [
    {
     "ename": "ValidationError",
     "evalue": "1 validation error for BedrockLLM\nstop_sequences\n  Extra inputs are not permitted [type=extra_forbidden, input_value=['\\n\\n'], input_type=list]\n    For further information visit https://errors.pydantic.dev/2.10/v/extra_forbidden",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValidationError\u001B[0m                           Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[5], line 13\u001B[0m\n\u001B[0;32m      7\u001B[0m retriever \u001B[38;5;241m=\u001B[39m tlr_vectorstore\u001B[38;5;241m.\u001B[39mas_retriever(\n\u001B[0;32m      8\u001B[0m     search_type\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmmr\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m      9\u001B[0m     search_kwargs\u001B[38;5;241m=\u001B[39m{\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mfetch_k\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;241m10\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mk\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;241m5\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mlambda_mult\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;241m0.5\u001B[39m}\n\u001B[0;32m     10\u001B[0m )\n\u001B[0;32m     12\u001B[0m \u001B[38;5;66;03m# 4.2 LLM de Bedrock con controles de generación\u001B[39;00m\n\u001B[1;32m---> 13\u001B[0m tlr_llm \u001B[38;5;241m=\u001B[39m \u001B[43mBedrockLLM\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m     14\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcredentials_profile_name\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mBEDROCK_PROFILE\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     15\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmodel_id\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mBEDROCK_MODEL_ID\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     16\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmax_tokens\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mLLM_MAX_TOKENS\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     17\u001B[0m \u001B[43m    \u001B[49m\u001B[43mstop_sequences\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mLLM_STOP_SEQUENCES\u001B[49m\n\u001B[0;32m     18\u001B[0m \u001B[43m)\u001B[49m\n\u001B[0;32m     20\u001B[0m \u001B[38;5;66;03m# 4.3 Prompt anti-repetición y cadena refine\u001B[39;00m\n\u001B[0;32m     21\u001B[0m prompt \u001B[38;5;241m=\u001B[39m ChatPromptTemplate\u001B[38;5;241m.\u001B[39mfrom_template(\n\u001B[0;32m     22\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m     23\u001B[0m \u001B[38;5;124;03mInformación relevante:\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m     30\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m     31\u001B[0m )\n",
      "File \u001B[1;32m~\\Desktop\\Clase\\Master\\UPM\\TFM\\Trabajo\\venv\\Lib\\site-packages\\langchain_core\\load\\serializable.py:130\u001B[0m, in \u001B[0;36mSerializable.__init__\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m    128\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21m__init__\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;241m*\u001B[39margs: Any, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs: Any) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    129\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"\"\"\"\u001B[39;00m  \u001B[38;5;66;03m# noqa: D419\u001B[39;00m\n\u001B[1;32m--> 130\u001B[0m     \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[38;5;21;43m__init__\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\Desktop\\Clase\\Master\\UPM\\TFM\\Trabajo\\venv\\Lib\\site-packages\\pydantic\\main.py:214\u001B[0m, in \u001B[0;36mBaseModel.__init__\u001B[1;34m(self, **data)\u001B[0m\n\u001B[0;32m    212\u001B[0m \u001B[38;5;66;03m# `__tracebackhide__` tells pytest and some other tools to omit this function from tracebacks\u001B[39;00m\n\u001B[0;32m    213\u001B[0m __tracebackhide__ \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[1;32m--> 214\u001B[0m validated_self \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m__pydantic_validator__\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mvalidate_python\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdata\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mself_instance\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m    215\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m validated_self:\n\u001B[0;32m    216\u001B[0m     warnings\u001B[38;5;241m.\u001B[39mwarn(\n\u001B[0;32m    217\u001B[0m         \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mA custom validator is returning a value other than `self`.\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m'\u001B[39m\n\u001B[0;32m    218\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mReturning anything other than `self` from a top level model validator isn\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mt supported when validating via `__init__`.\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    219\u001B[0m         \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mSee the `model_validator` docs (https://docs.pydantic.dev/latest/concepts/validators/#model-validators) for more details.\u001B[39m\u001B[38;5;124m'\u001B[39m,\n\u001B[0;32m    220\u001B[0m         stacklevel\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m2\u001B[39m,\n\u001B[0;32m    221\u001B[0m     )\n",
      "\u001B[1;31mValidationError\u001B[0m: 1 validation error for BedrockLLM\nstop_sequences\n  Extra inputs are not permitted [type=extra_forbidden, input_value=['\\n\\n'], input_type=list]\n    For further information visit https://errors.pydantic.dev/2.10/v/extra_forbidden"
     ]
    }
   ],
   "execution_count": 5,
   "source": [
    "# 4.1 Instanciar vectorstore y MMR retriever\n",
    "tlr_vectorstore = QdrantVectorStore(\n",
    "    client=qdrant_client,\n",
    "    collection_name=COLLECTION_NAME,\n",
    "    embedding=embedder\n",
    ")\n",
    "retriever = tlr_vectorstore.as_retriever(\n",
    "    search_type=\"mmr\",\n",
    "    search_kwargs={\"fetch_k\": 10, \"k\": 5, \"lambda_mult\": 0.5}\n",
    ")\n",
    "\n",
    "# 4.2 LLM de Bedrock con controles de generación\n",
    "tlr_llm = BedrockLLM(\n",
    "    credentials_profile_name=BEDROCK_PROFILE,\n",
    "    model_id=BEDROCK_MODEL_ID,\n",
    "    max_tokens=LLM_MAX_TOKENS,\n",
    "    stop_sequences=LLM_STOP_SEQUENCES\n",
    ")\n",
    "\n",
    "# 4.3 Prompt anti-repetición y cadena refine\n",
    "prompt = ChatPromptTemplate.from_template(f\"Información relevante:{context} Pregunta: {question} Por favor, responde de forma concisa en un único párrafo, sin repetir ideas ni frases.\"\n",
    ")\n",
    "tlr_qa_agent = RetrievalQA.from_chain_type(\n",
    "    llm=tlr_llm,\n",
    "    chain_type=\"refine\",\n",
    "    retriever=retriever,\n",
    "    return_source_documents=False,\n",
    "    chain_type_kwargs={\"prompt\": prompt}\n",
    ")"
   ],
   "id": "4d82859f7da778ef"
  },
  {
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-17T15:51:10.177921600Z",
     "start_time": "2025-05-17T15:51:10.176921200Z"
    }
   },
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Procesa un JSON de preguntas y escribe otro con respuestas\n",
    "def process_questions(input_json: str, output_json: str) -> None:\n",
    "    with open(input_json, 'r', encoding='utf-8') as f:\n",
    "        qa_list = json.load(f)\n",
    "\n",
    "    results = []\n",
    "    for item in qa_list:\n",
    "        q = item.get(\"Q\") or item.get(\"question\")\n",
    "        expected = item.get(\"A\") or item.get(\"expected_answer\")\n",
    "        print(f\"-> Pregunta: {q}\")\n",
    "        out = tlr_qa_agent.invoke({\"query\": q})\n",
    "        gen = out.get(\"result\", \"\").strip()\n",
    "        results.append({\"question\": q, \"expected_answer\": expected, \"generated_answer\": gen})\n",
    "\n",
    "    with open(output_json, 'w', encoding='utf-8') as f:\n",
    "        json.dump(results, f, ensure_ascii=False, indent=4)\n",
    "    print(f\"Resultados guardados en {output_json}\")\n",
    "\n",
    "# Ejecutar para ambos conjuntos si se invoca el notebook como script\n",
    "if __name__ == \"__main__\":\n",
    "    process_questions(\"Expert-questions.json\", \"Expert-questions-output.json\")\n",
    "    process_questions(\"Not-expert-questions.json\", \"Not-expert-questions-output.json\")"
   ],
   "id": "a7f890ffb2bbe653"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
